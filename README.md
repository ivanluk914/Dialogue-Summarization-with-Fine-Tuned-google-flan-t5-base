# Dialogue-Summarization-with-Fine-Tuned-google-flan-t5-base
Fine-tuning the `google/flan-t5-base` model for dialogue summarization using HuggingFace. This project explores full fine-tuning and parameter-efficient fine-tuning (PEFT) techniques like LoRA, evaluates model performance quantitatively with ROUGE metrics, and demonstrates significant improvements in summarization capabilities. >
